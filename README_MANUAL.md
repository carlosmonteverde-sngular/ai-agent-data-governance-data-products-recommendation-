# üìò Manual de Operaci√≥n: Agente de Recomendaci√≥n de Productos de Datos con IA

Este documento describe el flujo de trabajo completo para utilizar el Agente de IA que analiza metadatos de BigQuery y genera propuestas autom√°ticas de **Productos de Datos** (Data Products) para su gobierno.

## üîÑ Flujo del Proceso

El proceso consta de 3 etapas principales:

```mermaid
graph LR
    A[üöÄ Ejecuci√≥n del Agente] -->|Analiza Metadatos| B[üß† Genera Propuesta JSON];
    B -->|Crea Pull Request| C[üìù Revisi√≥n en GitHub];
    C -->|Humano Valida| D{‚úÖ ¬øAprobado?};
    D -- S√≠ (Merge) --> E[üìÇ Definici√≥n Consolidada];
```

---

## Prerequisitos

1. Activar el entorno virtual:
   ```bash
   .venv\Scripts\activate
   # O en Mac/Linux:
   source .venv/bin/activate
   ```
2. Instalar dependencias:
   ```bash
   pip install -r requirements.txt
   ```
3. Configurar credenciales de GCP (Application Default Credentials):
   ```bash
   gcloud auth application-default login
   ```
4. Configurar variables de entorno (ver `config/settings.py` o crear un `.env`).

### 1. üöÄ Ejecuci√≥n del Agente (Recomendaci√≥n)
El proceso comienza ejecutando el agente localmente o programado.

**Comando:**
```bash
python main.py
```

**Lo que hace el agente:**
1.  **Conecta a BigQuery** y lee los metadatos t√©cnicos (tablas, esquemas, descripciones) del dataset objetivo.
2.  Env√≠a este contexto a **Gemini 2.5 Flash**.
3.  Gemini analiza las relaciones sem√°nticas y sugiere **Productos de Datos** l√≥gicos, incluyendo:
    *   **Nombre** del producto.
    *   **Descripci√≥n** de negocio.
    *   **Dominio** sugerido (ej. Ventas, Log√≠stica).
    *   **Owner** propuesto.
    *   Lista de **tablas** que lo componen.
4.  Genera un archivo JSON local y abre una **Pull Request (PR)** en GitHub con la propuesta.

---

### 2. üìù Revisi√≥n Humana (Gobierno)
Un Data Steward o Arquitecto de Datos recibe la notificaci√≥n de la PR.

**Acciones:**
1.  Revisar el archivo JSON propuesto en la pesta√±a "Files changed".
2.  Evaluar si la agrupaci√≥n de tablas tiene sentido para el negocio.
3.  Validar o corregir los campos de `domain` y `owner`.
4.  Si est√° conforme, hace clic en **"Merge pull request"**.

---

### 3. üìÇ Consolidaci√≥n
Al aprobar (hacer merge) la PR, la definici√≥n del Producto de Datos queda versionada y aprobada en el repositorio (`output/data_products_proposal_....json`).

---

### 4. üöÄ Publicaci√≥n a Dataplex
Una vez aprobado el JSON, puedes ejecutar el script de publicaci√≥n para crear los **Entry Groups** correspondientes en Dataplex.

**Comando:**
```bash
python scripts/publish_data_products.py --file output/data_products_proposal_<TIMESTAMP>.json
```

**Opciones:**
*   `--dry-run`: Muestra qu√© se crear√≠a sin hacer cambios reales en Google Cloud.

**Resultado:**
*   Se crear√°n **Entry Groups** en Dataplex Catalog.
*   El `display_name` ser√° el nombre del Data Product.
*   La `description` incluir√° el dominio, owner y descripci√≥n de negocio.
*   *Nota: En esta versi√≥n, las tablas se listan en la descripci√≥n. La asignaci√≥n formal de "Entries" a estos Grupos es parte de la evoluci√≥n del roadmap.*

---

## üõ†Ô∏è Configuraci√≥n Requerida

Para que este flujo funcione, se necesitan los siguientes secretos o configuraciones:

1.  `GCP_PROJECT_ID`: ID del proyecto de Google Cloud.
2.  `GCP_LOCATION`: Ubicaci√≥n de los recursos (ej. `us-central1`).
3.  `GITHUB_TOKEN`: Token para crear Pull Requests (si se ejecuta en CI/CD o con el cliente de GitHub configurado).

---

## üí° Preguntas Frecuentes

**¬øQu√© criterio usa el agente para agrupar tablas?**
El agente utiliza el modelo Gemini para inferir relaciones sem√°nticas bas√°ndose en los nombres de las tablas, columnas y sus descripciones existentes en BigQuery.

**¬øPuedo modificar la propuesta antes de aprobarla?**
S√≠, puedes editar el archivo JSON directamente en la interfaz de GitHub (o en tu editor local antes de hacer push/merge) para ajustar nombres, owners o mover tablas entre productos.

**¬øC√≥mo cambio el dataset a analizar?**
Edita la variable `TARGET_DATASET` en `config/settings.py` o mediante variables de entorno.
